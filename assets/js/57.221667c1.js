(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{370:function(s,a,t){"use strict";t.r(a);var n=t(14),e=Object(n.a)({},(function(){var s=this,a=s._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"hashmap-哈希表常见问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hashmap-哈希表常见问题"}},[s._v("#")]),s._v(" HashMap：哈希表常见问题")]),s._v(" "),a("p",[s._v("JAVA8的HashMap利用了红黑树，所以其由 "),a("strong",[s._v("数组+链表+红黑树")]),s._v(" 组成。")]),s._v(" "),a("h3",{attrs:{id:"核心属性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#核心属性"}},[s._v("#")]),s._v(" 核心属性")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 数组table 也有人叫它桶 ")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 所有键值对的集合")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" entrySet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" threshold"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 负载因子")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),s._v(" loadFactor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 继承自父类的：")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("        keySet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Collection")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" hash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" next"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br")])]),a("h2",{attrs:{id:"threshold-是什么-怎么来的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#threshold-是什么-怎么来的"}},[s._v("#")]),s._v(" threshold 是什么，怎么来的")]),s._v(" "),a("p",[s._v("threshold是"),a("strong",[s._v("触发扩容的临界值")]),s._v("，threshold = 75，当存入第76个数，++size > threshold，触发resize()函数扩容")]),s._v(" "),a("p",[s._v("threshold的值由两个来源：")]),s._v(" "),a("ul",[a("li",[s._v("resize()根据负载因子和Cap计算得到，甚至可以说这也是唯一的途径")]),s._v(" "),a("li",[s._v("初始化"),a("strong",[s._v("指定Capacity")]),s._v("，会找到离Cap最近的2^n赋值给threshold")])]),s._v(" "),a("blockquote",[a("p",[s._v("这里是个误区，我们初始化指定的实际上就是Cap而不是threshold，threshold只是暂存一下Cap的值方便后续resize()时初始化而已，详细见："),a("code",[s._v("< 扩容处理Capacity 与 threshold >")]),s._v("章节")])]),s._v(" "),a("p",[s._v("为什么初始化"),a("strong",[s._v("指定的明明是Cap，却被赋值给了threshold")]),s._v("？")]),s._v(" "),a("p",[s._v("因为"),a("strong",[s._v("数组的长度length就是Cap")]),s._v("，我们没有必要在浪费4个字节去存储Cap。同时由于懒加载的思想，数组会等到第一次put时通过resize()扩容方法，做初始化。因此我们在初始化的时候，指定了Cap，却没办法赋值给Cap变量，因为没有；也没办法new数组，因为懒加载。")]),s._v(" "),a("p",[s._v("因此，既然threshold都是要依赖Cap计算而来的，那当然在Cap没有时，暂存Cap的值。节省4字节的空间。")]),s._v(" "),a("h2",{attrs:{id:"负载因子-loadfactor-是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#负载因子-loadfactor-是什么"}},[s._v("#")]),s._v(" 负载因子 loadFactor 是什么")]),s._v(" "),a("p",[s._v("负载因子从客观上来说它代表每个 bucket 桶存储的最大平均元素个数。但它存在的意义主观上来说是 "),a("strong",[s._v("帮助Cap计算threshold，让HashMap知道扩容的阈值")]),s._v("。在初始化会修改Cap，Cap * loadFactor可得threshold")]),s._v(" "),a("p",[s._v("new一个HashMap时，是我们指定loadFactor的唯一机会。除了初始化的时候指定，没有别的操作会修改loadFactor了，并且new了之后不可修改。loadFactor默认为0.75，一般也不建议修改。")]),s._v(" "),a("h3",{attrs:{id:"扩容时处理capacity-与-threshold"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#扩容时处理capacity-与-threshold"}},[s._v("#")]),s._v(" 扩容时处理Capacity 与 threshold")]),s._v(" "),a("p",[s._v("注释写的很清楚了：")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" oldTab "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 旧容量")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" oldCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldTab "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" oldTab"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 旧threshold ")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" oldThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" threshold"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" newCap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// oldCap > 0 已经不是第一次了")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 去掉了特殊情况的判断 理解为cap和thr一起翻倍即可")]),s._v("\n        newCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        newThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// double threshold")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// oldThr > 0 但oldCap = 0 这说明是第一次，且new时指定了初始容量")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// new时指定的初始容量会被暂存在threshold变量里，因为cap是数组的length，懒加载思想，当时数组仍未初始化")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    newCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldThr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("              \n     "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 说明是第一次，且new时 没有 指定初始容量")]),s._v("\n    newCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_INITIAL_CAPACITY")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    newThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_LOAD_FACTOR")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_INITIAL_CAPACITY")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 根据loadFactor计算 newThr")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),s._v(" ft "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("newCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" loadFactor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    newThr "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newCap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" ft "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("ft "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAX_VALUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\nthreshold "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newThr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br")])]),a("p",[s._v("后续：")]),s._v(" "),a("ul",[a("li",[s._v("创建一个新的Entry空数组，长度是原数组的2倍。")]),s._v(" "),a("li",[s._v("ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。 因为容量是2的幂，因此rehash的时候，只需要看新增的一位是0还是1即可，是0位置不变。这样避免了计算hash值，提高了效率。")])]),s._v(" "),a("h2",{attrs:{id:"为什么初始化时数组大小为16"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么初始化时数组大小为16"}},[s._v("#")]),s._v(" 为什么初始化时数组大小为16")]),s._v(" "),a("p",[a("strong",[s._v("更应该问：为什么大小必须是2的幂")])]),s._v(" "),a("p",[s._v("为了位运算的方便，比起取模，性能更高。")]),s._v(" "),a("p",[a("strong",[s._v("hash函数")]),s._v("：index = HashCode（Key） & （Length- 1）")]),s._v(" "),a("p",[s._v("那么 如果二进制 length-1 = 1111 做与运算相当于对16取模，因此实现了与运算和取模"),a("strong",[s._v("效果一样")]),s._v("，而性能更高。")]),s._v(" "),a("p",[a("strong",[s._v("(n - 1) & hash = n % hash")])]),s._v(" "),a("p",[s._v("16是一个经验值，不太大，也不会太小。")]),s._v(" "),a("h3",{attrs:{id:"题外话-如何找到离capacity最近的2-n"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#题外话-如何找到离capacity最近的2-n"}},[s._v("#")]),s._v(" 题外话：如何找到离capacity最近的2^n")]),s._v(" "),a("p",[s._v("tableSizeFor方法写的很巧妙，利用位运算最小化时间开销。")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 思路是：找到cap最高位的1 让后面所有的二进制位都变为1，然后+1即可")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// -1 是防止出现如：0000 1000 这样的数，本身就是2^n")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 为什么是右移5次?")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 假设最高位为x，第一次|，使 x ~ x + 1 为 1     1")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第2次|，使 x + 2 ~ x + 3 为1                2")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第3次|，使 x + 4 ~ x + 7 为1                4")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第4次|，使 x + 8 ~ x + 15 为1               8")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第5次|，使 x + 16 ~ x + 31 为1              16")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 因此最多可以处理 1+2+4+8+16 加上自己本身的1，32位，刚好等于一个int的位")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("tableSizeFor")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" cap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|=")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|=")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|=")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|=")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|=")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" n "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br")])]),a("h2",{attrs:{id:"为什么采用红黑树不用avl树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么采用红黑树不用avl树"}},[s._v("#")]),s._v(" 为什么采用红黑树不用AVL树")]),s._v(" "),a("p",[a("strong",[s._v("AVL树")]),s._v("：")]),s._v(" "),a("p",[s._v("严格平衡的二叉搜索树,必须满足"),a("strong",[s._v("所有节点的左右子树高度差不超过1")]),s._v("。")]),s._v(" "),a("p",[a("strong",[s._v("红黑树")]),s._v("：")]),s._v(" "),a("p",[s._v("红黑树"),a("strong",[s._v("确保没有一条路径会比其它路径长出两倍")]),s._v("。")]),s._v(" "),a("p",[s._v("因此红黑树的"),a("strong",[s._v("插入节点效率更高")]),s._v("，而AVL"),a("strong",[s._v("查找效率")]),s._v("更高。")]),s._v(" "),a("p",[s._v("因为concurrenthashmap的put操作会加锁，阻塞后续的put/get，因此我们希望插入的效率要高一些。")]),s._v(" "),a("p",[s._v("红黑树节点小于6也是会退化成链表的。")]),s._v(" "),a("h2",{attrs:{id:"什么对象可以作为key"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么对象可以作为key"}},[s._v("#")]),s._v(" 什么对象可以作为key")]),s._v(" "),a("ol",[a("li",[s._v("重写hashcode")]),s._v(" "),a("li",[s._v("重写equals")]),s._v(" "),a("li",[s._v("对象不可变，这个往往是容易被忽略的一点")])]),s._v(" "),a("p",[s._v("比如Integer的实现类如下：")]),s._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 包装了 一个 int 且用final修饰 ")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("String类的char数组同样有 final 修饰")]),s._v(" "),a("p",[s._v("也就是key必须是不可变的。为什么？")]),s._v(" "),a("p",[s._v("因为如果被修改了，那么equals，hashcode方法都会变，但你hashcode到的位置已经固定了")]),s._v(" "),a("h2",{attrs:{id:"hashmap死锁问题-尾插法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hashmap死锁问题-尾插法"}},[s._v("#")]),s._v(" HashMap死锁问题，尾插法")]),s._v(" "),a("p",[s._v("多线程扩容的时候，头插法，会导致链表成环，于是while将会一直循环下去，形成死循环，不停增大JVM开销，最后内存溢出。")]),s._v(" "),a("p",[s._v("因此后来修改为：向链表插入数据时是"),a("strong",[s._v("尾插法")]),s._v("。")]),s._v(" "),a("blockquote",[a("p",[s._v("因为头插会引起死循环：Java7(头插)在多线程操作HashMap时可能引起死循环，原因是扩容转移后前后"),a("strong",[s._v("链表顺序倒置(头插入导致)")]),s._v(" ，在转移过程中修改了原来链表中节点的引用关系。")])]),s._v(" "),a("h2",{attrs:{id:"hashmap会缩容吗"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hashmap会缩容吗"}},[s._v("#")]),s._v(" HashMap会缩容吗")]),s._v(" "),a("p",[s._v("HashMap没有缩容机制（redis的dict有）。但是红黑树节点小于6也是会退化成链表的。")])])}),[],!1,null,null,null);a.default=e.exports}}]);