(window.webpackJsonp=window.webpackJsonp||[]).push([[77],{402:function(s,a,t){"use strict";t.r(a);var n=t(14),e=Object(n.a)({},(function(){var s=this,a=s._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"hash-哈希表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash-哈希表"}},[s._v("#")]),s._v(" Hash：哈希表")]),s._v(" "),a("h2",{attrs:{id:"hash常用命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash常用命令"}},[s._v("#")]),s._v(" Hash常用命令")]),s._v(" "),a("h4",{attrs:{id:"基本读写-hset-hget"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本读写-hset-hget"}},[s._v("#")]),s._v(" 基本读写：hset/hget")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hset "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nhget "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("h4",{attrs:{id:"批量读写-hmget"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#批量读写-hmget"}},[s._v("#")]),s._v(" 批量读写：HMGET")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 批量执行:mget")]),s._v("\nHMSET "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("value1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("value2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" \nHMGET "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("h4",{attrs:{id:"读所有key-value-hkeys"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#读所有key-value-hkeys"}},[s._v("#")]),s._v(" 读所有key/value：hkeys")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 只读出所有key")]),s._v("\nhkeys "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 只读出所有value")]),s._v("\nhvals "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 读出所有key - value")]),s._v("\nhgetall "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("h4",{attrs:{id:"查元素个数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查元素个数"}},[s._v("#")]),s._v(" 查元素个数")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hlen "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h4",{attrs:{id:"删除-hdel"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#删除-hdel"}},[s._v("#")]),s._v(" 删除：hdel")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hdel "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h4",{attrs:{id:"查询key是否存在-hexists"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查询key是否存在-hexists"}},[s._v("#")]),s._v(" 查询key是否存在：hexists")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hexists "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h4",{attrs:{id:"key不存在才生效-hsetnx"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key不存在才生效-hsetnx"}},[s._v("#")]),s._v(" key不存在才生效：HSETNX")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hsetnx "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("需要注意的是，NX针对的是 "),a("code",[s._v("[key]")]),s._v(" ，而非 "),a("code",[s._v("[HashKey]")]),s._v(" 。")]),s._v(" "),a("h4",{attrs:{id:"加减运算-hincrby"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#加减运算-hincrby"}},[s._v("#")]),s._v(" 加减运算：hincrby")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hincrby "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("HashKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("diff"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# HashKey -> key -> value += diff")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("blockquote",[a("p",[s._v("浮点运算还是加float hincrbyfloat")])]),s._v(" "),a("h2",{attrs:{id:"hash底层实现原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash底层实现原理"}},[s._v("#")]),s._v(" Hash底层实现原理")]),s._v(" "),a("h3",{attrs:{id:"ziplist-listpack-数组"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ziplist-listpack-数组"}},[s._v("#")]),s._v(" ziplist / listpack （数组）")]),s._v(" "),a("p",[s._v("当一个 hash对象只包含「"),a("strong",[s._v("少量键值对")]),s._v("」且每个键值对的kv「"),a("strong",[s._v("要么就是小整数要么就是长度比较短的字符串")]),s._v("」，那么它用 ziplist 作为底层实现，相关的参数是"),a("code",[s._v("hash-zipmap-max-entries")]),s._v("。")]),s._v(" "),a("blockquote",[a("p",[s._v("在 Redis 7.0 中，ziplist已经废弃了，交由 listpack 数据结构来实现了。")])]),s._v(" "),a("p",[s._v("重点是下面的dict。")]),s._v(" "),a("h2",{attrs:{id:"dict-字典-哈希表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dict-字典-哈希表"}},[s._v("#")]),s._v(" dict：字典 哈希表")]),s._v(" "),a("p",[s._v("底层是个Hash表，源码有两个hash，一个是为了扩容而存在的。")]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// dict字典")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dict")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 这是个一维数组 元素为 dictEntry的指针")]),s._v("\n    dictEntry "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//类型特定函数")]),s._v("\n    dictType "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//hash 表的大小")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" sizemask"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// mask 计算索引值")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" used"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 表示已经使用的个数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("privdata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 2个哈希表")]),s._v("\n    dictht ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// dict内部的键值对")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("typedef")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictEntry")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("union")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("val"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("uint64_t")]),s._v(" u64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("int64_t")]),s._v(" s64"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("double")]),s._v(" d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("struct")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("dictEntry")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("next"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 解决哈希冲突，链式存储")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" dictEntry"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br")])]),a("h4",{attrs:{id:"解决哈希冲突-链式存储"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决哈希冲突-链式存储"}},[s._v("#")]),s._v(" 解决哈希冲突：链式存储")]),s._v(" "),a("p",[s._v("发生哈希冲突时，也是用链表存储的，这和Java的HashMap一样，但不会转化为红黑树")]),s._v(" "),a("h4",{attrs:{id:"扩容实现原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#扩容实现原理"}},[s._v("#")]),s._v(" 扩容实现原理")]),s._v(" "),a("p",[s._v("当元素数量等于数组长度时就会进行扩容操作。")]),s._v(" "),a("blockquote",[a("p",[s._v("生成 RDB 和重写 AOF的过程中，不允许rehash")])]),s._v(" "),a("div",{staticClass:"language-c line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("dictExpand")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dict "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    dictht n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 扩容后的状态")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unsigned")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" realsize "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("_dictNextPower")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 初始化扩容后的字典元数据")]),s._v("\n    n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" realsize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sizemask "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" realsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("table "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("zcalloc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("realsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("sizeof")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dictEntry"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("used "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第一次初始化")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("table "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[s._v("NULL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        d"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" DICT_OK"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 放入新 ht[1] 中")]),s._v("\n    d"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("ht"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 打上 rehash 标记")]),s._v("\n    d"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("rehashidx "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" DICT_OK"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("h4",{attrs:{id:"缩容触发时机"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#缩容触发时机"}},[s._v("#")]),s._v(" 缩容触发时机")]),s._v(" "),a("p",[s._v("当字典的使用容量不足总空间的 10% 时（负载因子小于0.1），就会触发缩容，同样打上rehash标记")]),s._v(" "),a("h3",{attrs:{id:"关键-渐进式rehash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#关键-渐进式rehash"}},[s._v("#")]),s._v(" 关键：渐进式rehash")]),s._v(" "),a("p",[s._v("我们知道触发了扩容缩容仅仅是打上 rehash 标记并做初始化，什么时候真正执行rehash呢？有两个触发时机：我们依次来看，先对初始化做一些必要的说明。")]),s._v(" "),a("h4",{attrs:{id:"_0、初始化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_0、初始化"}},[s._v("#")]),s._v(" 0、初始化")]),s._v(" "),a("p",[s._v("会同时保留两个新旧hash结构，新hash的大小为「大于等于使用量的二的幂」")]),s._v(" "),a("p",[s._v("同时维护一个 "),a("code",[s._v("rehashIndex")]),s._v(" 变量，表示现在rehash到了数组的哪里，每次rehash的单位为桶，即一个bucket，随后"),a("code",[s._v("rehashIndex+1")]),s._v("；")]),s._v(" "),a("h4",{attrs:{id:"_1、定时任务"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、定时任务"}},[s._v("#")]),s._v(" 1、定时任务")]),s._v(" "),a("p",[s._v("定时进行一次rehash，如每 100ms/ 次")]),s._v(" "),a("p",[s._v("每次执行时长不会超过 1ms")]),s._v(" "),a("h4",{attrs:{id:"_2、发生crud操作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、发生crud操作"}},[s._v("#")]),s._v(" 2、发生CRUD操作")]),s._v(" "),a("p",[s._v("每次发生CRUD操作，进行一次rehash。")]),s._v(" "),a("h4",{attrs:{id:"rehash具体行为"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rehash具体行为"}},[s._v("#")]),s._v(" rehash具体行为")]),s._v(" "),a("p",[s._v("调用 dictRehash 函数，dictRehash 函数会把 ht[0] 中的元素依次添加到新的 Hash 表 ht[1] 中")]),s._v(" "),a("h4",{attrs:{id:"rehash期间的操作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rehash期间的操作"}},[s._v("#")]),s._v(" rehash期间的操作")]),s._v(" "),a("ul",[a("li",[s._v("新增操作，都只会在ht[1]中发生；")]),s._v(" "),a("li",[s._v("查询操作，会先去ht[0]中查找，然后再到ht[1]中查找；")]),s._v(" "),a("li",[s._v("删改同查询。")])]),s._v(" "),a("h3",{attrs:{id:"dict-vs-java-hashmap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dict-vs-java-hashmap"}},[s._v("#")]),s._v(" dict vs Java-HashMap")]),s._v(" "),a("p",[s._v("对于redis而言，内存空间十分宝贵，因此主要是为了节省空间，为此:")]),s._v(" "),a("ul",[a("li",[s._v("dict有缩容，HashMap没有")]),s._v(" "),a("li",[s._v("dict链表不会转化为红黑树，HashMap会")]),s._v(" "),a("li",[s._v("Redis解决哈希冲突的链式存储采用**「头插法」**，HashMap曾经也是，但后来改成了尾插法，这是因为Redis单线程不需要担心死锁问题。")])]),s._v(" "),a("p",[s._v("同时，因为redis单线程的缘故，为了避免服务暂停阻塞，采用渐进式Hash")]),s._v(" "),a("h3",{attrs:{id:"hash唯一约束-键值对个数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash唯一约束-键值对个数"}},[s._v("#")]),s._v(" Hash唯一约束：键值对个数")]),s._v(" "),a("p",[s._v("Hash的键值对个数上限是：4,294,967,295 (2^32 - 1)")])])}),[],!1,null,null,null);a.default=e.exports}}]);